import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from streamlit_ace import st_ace

from scipy.integrate import odeint
from scipy.optimize import fsolve
import time

import time
import io
import sys

def uravnenie_1z():
    st.markdown("""
    ### 5. ВЫЧИСЛЕНИЕ КОРНЕЙ УРАВНЕНИЙ

    #### 5.1. Уравнения с одним неизвестным
    Пусть задана непрерывная функция \( f(x) \) и требуется найти все (или некоторые) корни уравнения
    $$ f(x) = 0. $$

    Эта задача включает несколько этапов:

    1. Необходимо исследовать количество, характер (простые или кратные корни, действительные или комплексные) и расположение корней.
    2. Необходимо найти приближенные значения корней.
    3. Для интересующих нас значений корней провести их вычисление с требуемой точностью.

    Первый и второй этапы рассматриваются аналитически и графически. Когда требуется найти только действительные корни, очень часто оказывается полезным составить таблицу значений и найти зоны смены знака \( f(x) \).
    """)

def metod_dihotomii():
    st.markdown("""
    ### 5.1.1. Метод дихотомии (половинного деления)
    Пусть известно, что \( f(x) \) непрерывна на \( [a,b] \) и \( f(a) \cdot f(b) < 0 \), т.е. функция \( f(x) \) принимает на концах отрезка значения разных знаков. В этом случае отрезок \( [a,b] \) содержит нечётное число корней уравнения:

    $$ f(x) = 0. \tag{1} $$

    Положим \( x_0 = a, x_1 = b \), найдём середину \( x_2 \) отрезка \( [x_0, x_1] \):

    $$ x_2 = \frac{x_0 + x_1}{2}, $$

    и вычислим \( f(x_2) \). Если \( f(x_2) \cdot f(x_1) \leq 0 \), то в качестве нового отрезка для рассмотрения выберем \( [x_0, x_2] \), в противном случае, при \( f(x_2) \cdot f(x_0) \leq 0 \), выберем отрезок \( [x_2, x_1] \). Очевидно, что на выбранном таким образом новом отрезке будет не менее одного корня уравнения (1). С этим отрезком вновь повторяем изложенную выше процедуру и так далее. В результате мы получаем систему вложенных друг в друга отрезков:

    $$ [a_0, b_0], [a_1, b_1], [a_2, b_2], \dots [a_n, b_n], \dots $$

    где

    $$ a_0 = a, b_0 = b, a_1 = x_2, b_1 = b, a_2 = \frac{a_0 + x_2}{2}, b_2 = x_2, $$

    при этом

    $$ f(a_n) \cdot f(b_n) < 0, b_n - a_n = \frac{b - a}{2^n}. $$

    Так, за 10 вычислений функции мы уменьшим область локализации корня в ~ \( 10^3 \) раз.

    Метод дихотомии применим и к недифференцируемым функциям, прост и надёжен, с гарантируемой точностью ответа. Однако метод имеет ряд недостатков:

    1. Необходимо знать отрезок \( [a,b] \), на котором происходит смена знака функции \( f(x) \).
    2. Если на \( [a,b] \) несколько корней, то неизвестно заранее, к какому корню сойдётся процесс.
    3. Метод неприменим к корням чётной кратности, для корней нечётной кратности метод может быть чувствителен к ошибкам округления.
    4. Не обобщается на системы уравнений.
    """)

    st.markdown("""
    Для нахождения всех корней с высокой точностью необходимо исключать уже найденные корни, чтобы избежать возможности замены близко лежащих корней уравнения \( f(x) = 0 \) на один приближённый корень. После того как очередной корень найден, отрезки локализации неизвестных корней надо находить, исключив из исходного отрезка \( [a,b] \) зоны локализации уже найденных корней.
    """)

def metod_hord():
    st.markdown("""
    ### 5.1.2. Метод хорд
    Иногда вместо метода половинного деления используют метод хорд, в надежде на более быстрое получение ответа. Пусть \( x^* \) — корень уравнения

    $$ f(x) = 0, \tag{1} $$

    отделен на \( [a,b] \) (т.е. других корней на этом отрезке нет) и \( f(a) \cdot f(b) < 0 \).

    Проведём прямую через точки \( (a, f(a)) \) и \( (b, f(b)) \) и найдём её пересечение с осью OX:

    $$ x_1 = \frac{a f(b) - b f(a)}{f(b) - f(a)}. $$

    Далее, как в методе дихотомии, вычислим \( f(x_1) \), выберем новый отрезок \( [a,x_1] \) или \( [x_1,b] \) и так далее. Пусть, для определённости, \( f^{\prime\prime}(x) > 0 \) на \( [a,b] \) (т.е. хорда лежит выше кривой). Тогда возможны два случая:

    - Если \( f(a) > 0 \), то конец \( x = a \) неподвижен, и
    $$ x_{n+1} = x_n - \frac{f(x_n)}{f(x_n) - f(a)} \cdot (x_n - a). $$
    Это ограниченная монотонно убывающая последовательность.

    - Если \( f(a) < 0 \), то конец \( x = b \) неподвижен, и
    $$ x_{n+1} = x_n - \frac{f(x_n)}{f(x_n) - f(b)} \cdot (x_n - b). $$
    Это ограниченная монотонно возрастающая последовательность.

    В общем случае неподвижен тот конец \( x = a \), где знаки \( f^{\prime\prime}(x) \) и \( f(a) \) одинаковы, а последовательные приближения лежат по ту сторону \( x^* \), где \( f(x) f^{\prime\prime}(x) < 0 \).

    Предельным переходом в \( (1') \) и \( (1'') \) находим, что предел этих последовательностей есть корень уравнения \( x^* : f(x^*) = 0 \) (по условию единственный). Метод хорд не всегда лучше метода половинного деления.
    """)

def simple_iterecia():
    st.markdown("""
    ### 5.1.3. Метод простой итерации
    Сущность этого метода заключается в замене исходного уравнения вида

    $$ x = \varphi(x), \tag{2} $$

    (например, можно положить \( \varphi(x) = x + \psi(x)f(x) \), где \( \psi(x) \) — непрерывная знакопостоянная функция). Метод простой итерации реализуется следующим образом. Выберем из каких-либо соображений приближённое (может быть, очень грубое) значение корня \( x_0 \) и подставим в правую часть (2), тогда получим некоторое число:

    $$ x_1 = \varphi(x_0). $$

    Подставляя в правую часть \( x_1 \), получим \( x_2 \) и так далее. Таким образом, возникает некоторая последовательность чисел:

    $$ x_0, x_1, x_2, \dots, x_n, \dots, $$

    где

    $$ x_n = \varphi(x_{n-1}). \tag{3} $$

    Если эта последовательность сходится, т.е. существует

    $$ x^* = \lim_{n \to \infty} x_n, $$

    то \( x^* \) будет корнем уравнения (2), который, используя (3), можно вычислить с любой степенью точности.
    """)

    st.markdown("""
    В приложениях часто весьма полезно представить графически интерпретацию итерационного процесса (3), начертив графики функций \( y = x \) и \( y = \varphi(x) \).

    Установим достаточные условия сходимости.

    **Теорема 1**. Пусть функция \( \varphi(x) \) определена и дифференцируема на \( [a,b] \), и все её значения \( \varphi(x) \in [a,b] \). Тогда, если выполнено условие

    $$ |\varphi'(x)| \leq q < 1, \tag{4} $$

    при \( x \in [a,b] \), то:

    1) итерационный процесс (3) сходится независимо от начального приближения \( x_0 \in [a,b] \);
    2) \( x^* = \lim_{n \to \infty} x_n \) — единственный корень уравнения \( x = \varphi(x) \) на \( [a,b] \).

    **Доказательство**:

    Пусть

    $$ x_{n+1} = \varphi(x_n), \quad x_n = \varphi(x_{n-1}), $$

    тогда

    $$ x_{n+1} - x_n = \varphi(x_n) - \varphi(x_{n-1}). $$

    По теореме Лагранжа имеем:

    $$ x_{n+1} - x_n = \varphi'(x_n^*) (x_n - x_{n-1}), \quad x_n^* \in [x_{n-1}, x_n]. $$

    Поэтому в силу (4):

    $$ |x_{n+1} - x_n| \leq q |x_n - x_{n-1}|. $$

    Отсюда, полагая последовательно \( n = 1, 2, \dots \), находим:

    $$ |x_{n+1} - x_n| \leq q^n |x_1 - x_0|. \tag{5} $$

    Рассмотрим ряд:

    $$ x_0 + (x_1 - x_0) + (x_2 - x_1) + \dots + (x_n - x_{n-1}) + \dots. \tag{6} $$

    Очевидно, частные суммы этого ряда равны \( s_n = x_n \).

    Для этого ряда имеем, согласно (5), что его члены меньше по абсолютной величине членов геометрической прогрессии со знаменателем \( q < 1 \). Поэтому этот ряд сходится абсолютно и:

    $$ \lim_{n \to \infty} s_n = x^* \in [a,b]. $$

    Переходя к пределу в (3), в силу непрерывности \( \varphi(x) \) получим:

    $$ x^* = \varphi(x^*). $$

    Таким образом, \( x^* \) — действительно корень уравнения (2), который единственен.
    """)

def newton_method():
    st.markdown("""
    ### 5.1.4. Метод Ньютона
    Этот метод иногда ещё называют методом касательных или методом линеаризации. Пусть корень \( x^* \) уравнения

    $$ f(x) = 0 $$

    отделён на \( [a,b] \), и \( f'(x), f''(x) \) непрерывны и сохраняют определённые знаки на \( [a,b] \). Если известно какое-либо приближение \( x_n \) для \( x^* \), мы его можем уточнить, используя метод Ньютона. Положим:

    $$ h_n = x^* - x_n. $$

    Тогда:

    $$ 0 = f(x_n + h_n) \approx f(x_n) + h_n f'(x_n), $$

    и, следовательно:

    $$ h_n = - \frac{f(x_n)}{f'(x_n)}. $$

    Таким образом, можно ожидать, что:

    $$ x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)} \tag{10} $$

    окажется лучшим приближением для \( x^* \).
    """)

    st.markdown("""
    Можно дать другой вывод формулы (10). Напишем уравнение касательной, проходящей через \( (x_n, f(x_n)) \) и имеющей наклон \( f'(x_n) \):

    $$ y = f(x_n) + (x - x_n) f'(x_n), $$

    и найдём её точку пересечения с осью OX:

    $$ x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}, $$

    т.е. получилась та же формула (10).
    """)

    st.markdown("""
    Метод Ньютона является частным случаем метода простой итерации, для него:

    $$ \varphi(x) = x - \frac{f(x)}{f'(x)}. $$

    Вычислим \( \varphi'(x) \), которая определяет сходимость итерационного процесса:

    $$ \varphi'(x) = 1 - \frac{f'(x)^2 - f(x) f''(x)}{f'(x)^2}. $$

    Если \( x^* \) — простой корень уравнения \( f(x) = 0 \), то \( \varphi'(x^*) = 0 \); если \( x^* \) — \( p \)-кратный корень, то вблизи \( x^* \):

    $$ f(x) \approx a(x - x^*)^p, \quad f'(x) \approx pa(x - x^*)^{p-1}, $$

    и тогда:

    $$ \varphi'(x^*) = 1 - \frac{1}{p}, \quad \Rightarrow \quad |\varphi'(x^*)| < 1. $$

    Таким образом, если начальное приближение выбрано близким к \( x^* \), то метод Ньютона приведёт к сходящимся итерациям.
    """)

    st.markdown("""
    #### Теорема 2:
    Если \( f(a) f(b) < 0 \), \( f'(x), f''(x) \) отличны от нуля и знакопостоянны на \( [a,b] \), а начальное приближение удовлетворяет условию:

    $$ f(x_0) f''(x_0) > 0, \tag{11} $$

    то итерационный процесс (10) сходится.

    #### Доказательство:
    Пусть, например, \( f(a) < 0, f(b) > 0, f'(x) > 0, f''(x) > 0 \) при \( a \leq x \leq b \) (остальные случаи рассматривают аналогично). Положим \( x_0 = b \) и покажем, что все \( x_n > x^* \).

    В самом деле, пусть при некотором \( n \, x_n > x^* \), тогда:

    $$ x^* = x_n - \frac{f(x_n)}{f'(x_n)}. $$

    Учтём, что:

    $$ f'(x_n) > 0, \quad f'(x^*) > 0, \quad \Rightarrow \quad x^* < x_n. $$

    Таким образом, в условиях теоремы формула (10) даёт монотонно убывающую ограниченную последовательность, имеющую предел \( \bar{x} \). Переходя в (10) к пределу, находим:

    $$ \bar{x} = x - \frac{f(\bar{x})}{f'(\bar{x})}. $$

    т.е. \( \bar{x} = x^* \), что и требовалось доказать.
    """)

    st.markdown("""
    Получим оценку скорости сходимости вблизи простого корня. По определению простых итераций:

    $$ x_n - x^* = \varphi(x_{n-1}) - \varphi(x^*) = (x_{n-1} - x^*) \varphi'(x^*) + \frac{1}{2} (x_{n-1} - x^*)^2 \varphi''(x), $$

    где \( \tilde{x} \in (x_{n-1}, x^*) \).

    Таким образом, погрешность очередного приближения примерно равна квадрату погрешности предыдущего приближения (квадратичная сходимость); если \( (n-1) \)-я итерация давала 3 верных знака, то \( n \)-я даст 6, а \( (n+1) \)-я — 12 верных знаков. Конечно, это верно лишь вблизи корня, поэтому метод Ньютона используется для уточнения корней.

    #### Пример:
    Рассмотрим уравнение \( f(x) = x^2 - a \), исходя из метода Ньютона:

    $$ \varphi(x) = x - \frac{f(x)}{f'(x)} = \frac{x + \frac{a}{x}}{2}. $$

    Это известная формула для нахождения квадратного корня.
    """)

    st.markdown("""
    ### Замечания:
    1. Метод Ньютона при вычислении кратных корней, когда \( f'(x^*) = 0 \), надо применять, обеспечивая высокую точность вычисления \( f'(x) \) и \( f''(x) \).
    2. Если производная \( f'(x) \) на рассматриваемом отрезке меняется незначительно, то в методе Ньютона её можно считать постоянной на каждом шаге итераций, что сохраняет сходимость для нескольких итераций.
    3. Если известна кратность корня \( p \), то итерации по Ньютону выгоднее вести по формуле:

    $$ x_{n+1} = x_n - p \frac{f(x_n)}{f'(x_n)}, $$

    что повышает скорость сходимости.
    """)

def metod_sekushchih():
    st.markdown("""
    ### 5.1.5. Метод секущих

    В методе Ньютона требуется вычислять производную, что не всегда удобно. Иногда применяется метод, в котором точная производная заменена на первую разделённую разность, вычисленную по двум последним итерациям, т.е. касательная заменена на секущую. Для этого метода надо задать формулу:

    $$ x_{n+1} = x_n - \frac{(x_n - x_{n-1}) f(x_n)}{f(x_n) - f(x_{n-1})}. \tag{12} $$

    Для оценки скорости сходимости разложим все функции в ряд Тейлора в окрестности простого корня \( x^* \):

    $$ f(x_n) = f'(x^*)(x_n - x^*) + \frac{1}{2} f''(x^*)(x_n - x^*)^2, $$

    $$ f(x_{n-1}) = f'(x^*)(x_{n-1} - x^*) + \frac{1}{2} f''(x^*)(x_{n-1} - x^*)^2. $$

    Тогда

    $$ x_{n+1} = x_n - \frac{(x_n - x_{n-1}) f'(x^*)(x_n - x^*) \left(1 + \frac{1}{2} \frac{f''(x^*)}{f'(x^*)}(x_n + x_{n-1} - 2x^*) \right)}{f'(x^*)(x_n - x_{n-1}) \left( 1 + \frac{1}{2} \frac{f''(x^*)}{f'(x^*)} (x_n + x_{n-1} - 2x^*) \right)}. $$

    Введём обозначения: \( z_n = x_n - x^*, a = \frac{f''(x^*)}{2 f'(x^*)} \), тогда предыдущее соотношение запишется следующим образом:

    $$ z_{n+1} = a z_n z_{n-1}. $$

    Будем искать решение этого уравнения в виде

    $$ z_n+1 = a z_n^\alpha z_{n-1}^\beta. $$

    Из соотношения \( z_{n+1} = a z_n z_{n-1} \) имеем

    $$ z_{n-1} = z_n^{\frac{\alpha}{\beta}}, $$

    следовательно,

    $$ a z_n^\alpha z_n^{\frac{\alpha}{\beta}} = a z_n z_{n-1}, $$

    Отсюда для \( \alpha, \beta \) получаем следующие уравнения:

    $$ \beta^2 - \beta - 1 = 0, $$

    $$ \alpha \beta = 1. $$

    Нам надо выбрать корень \( \beta > 0 \), поэтому

    $$ \beta = \frac{1}{2} ( \sqrt{5} + 1) \approx 1.62. $$

    Таким образом, метод секущих хотя и имеет сверхлинейную сходимость, но скорость её меньше, чем в методе Ньютона. Однако в методе Ньютона при вычислениях надо знать и функцию, и производную, т.е. делать вдвое больше работы, чем в методе секущих. Поэтому для одного объёма вычислений в методе секущих можно сделать вдвое больше итераций и получить большую точность, чем в методе Ньютона.

    В \( (12) \) в знаменателе стоит разность значений функции; вблизи корня (особенно кратного) значения \( f(x_n), f(x_{n-1}) \) малы и близки, следовательно, при вычитании возможна потеря значащих цифр. Это ограничивает точность, с которой можно найти корень. Для повышения точности при малых значениях разности применяется приём Гарвика: задаётся не слишком малое \( \varepsilon \), и итерации ведутся до выполнения условия

    $$ |x_{n+1} - x_n| < \varepsilon, $$

    затем они продолжаются до тех пор, пока \( |x_{n+1} - x_n| \) убывает; первое возрастание свидетельствует о начале потери точности, и вычисления прекращают.
    """)

def metod_rybakova():
    st.markdown("""
    ### 5.1.6. Метод Рыбакова Л.М.

    Этот метод позволяет вычислить все действительные корни уравнения \( f(x) = 0 \) ( \( f \) — дифференцируемая функция) на \( [a,b] \), если известна оценка модуля \( f'(x) \):

    $$ \max_{a \leq x \leq b} |f'(x)| \leq M. \tag{13} $$

    Пусть \( M \) в (13) известно, возьмем \( x_0 = a \) и построим последовательность

    $$ x_{k+1} = x_k + \frac{f(x_k)}{M}, \quad k = 0,1, \dots $$

    Обозначим через \( x^* \) ближайший к \( a \) корень \( f(x) = 0 \), тогда

    $$ x_k < x_{k+1} \leq x^*. $$

    В самом деле, первое неравенство очевидно, второе неравенство доказывается так:

    $$ f(x_k) = f(x_k) - f(x^*) = f'(x_n) (x_k - x^*), \quad x_n \in [x_k, x^*]. $$

    Отсюда, при \( x_k < x^* \), имеем

    $$ \frac{f(x_k)}{f'(x_n)} = x_k - x^* \leq \frac{1}{M} |f'(x_n)| (x_k - x^*), $$

    или

    $$ x_{k+1} = x_k + \frac{f(x_k)}{M} = x^* - \left(x^* - x_k \right)\left(1 - \frac{1}{M}|f'(x_n)| \right). $$

    Таким образом, процесс (14) дает монотонно возрастающую ограниченную последовательность, в силу непрерывности \( f(x) \) её предел будет совпадать с \( x^* \). После того как корень \( x^* \) найден с нужной точностью \( \varepsilon \), положим в качестве начального приближения \( x_0 = x^* \), и по формуле (14) получим следующий корень и т.д.

    Метод Рыбакова, хотя и требует большого объёма вычислений для получения корней с высокой точностью, является единственным методом, гарантированно находящим все корни на \( [a,b] \) с заданной точностью.

    Описание усовершенствованного метода Рыбакова можно найти в книге В. Л. Загускина "Численные методы решения плохо обусловленных задач". Изд-во Ростовского университета, 1976 г.
    """)

def korni_mnogochlenov():
    st.markdown("""
    ### 5.1.7. Вычисление корней многочленов

    Задача вычисления корней многочленов часто встречается в приложениях, и вопрос этот давно привлекает внимание вычислителей. Как правило, в математобеспечении ЭВМ имеются программы для решения этой задачи, основанные на том или ином методе. Существуют методы, позволяющие найти все действительные и комплексные корни многочленов и не требующие предварительного отделения корней. Естественно, что если корни отделены, то к многочленам можно применить любой из рассмотренных выше методов. По способам вычисления корней многочленов существует обширная литература (см., например, [1]). Поэтому ограничимся некоторыми замечаниями.

    Сначала обсудим вопрос устойчивости значений корней к погрешностям в коэффициентах многочлена (корректность задачи отделения корней). Рассмотрим широко известный пример (см. книгу Д. Форсайта, М. Малькольма, К. Мойлер. "Машинные методы математических вычислений". М., Мир, 1980 г.).

    Пусть требуется найти корни многочлена

    $$ P(x) = (x - 1)(x - 2)\dots(x - 20) = x^{20} - 210x^{19} + \dots $$

    и корни хорошо разделены. Теперь предположим, что нам задали многочлен

    $$ P(x) = x^{20} - (210 - 2^{-23}) x^{19} + \dots, $$

    у которого "испортен" коэффициент при \( x^{19} \). Вычисления корней этого многочлена, проведённые с высокой точностью, показали, что 10 корней стали комплексными с мнимой частью от \( \pm 0.6 \) до \( \pm 2.8 \)! Сравнительно малое изменение (в шестом знаке после запятой) лишь одного коэффициента сильно изменило действительные корни, что является примером чувствительности задачи отделения корней. Таким образом, задача оказалась некорректной.

    Установим причину некорректности: малая ошибка породила большую ошибку в корнях. Эти задачи называются некорректными.

    Рассмотрим причину такой некорректности. Рассмотрим многочлен

    $$ P(x, \alpha) = x^{20} - (210 - \alpha) x^{19} + \dots $$

    и найдём зависимость корней уравнения \( P(x, \alpha) = 0 \) от \( \alpha \). Имеем:

    $$ \frac{\partial P}{\partial x} = 20 x^{19}, \quad \frac{\partial P}{\partial \alpha} = x^{19}, $$

    отсюда при \( x_i = i \) находим

    $$ \frac{\partial x_i}{\partial \alpha} = \frac{20}{\prod_{j = 1, j \neq i}^{20} (i - j)}. $$

    Для корня \( x_i = i \) получим

    $$ \frac{\partial x_i}{\partial \alpha} = \frac{20}{\prod_{j = 1, j \neq i}^{20} (i - j)}. $$

    Наибольшие значения производной \( (\sim 10^7 - 10^9) \) приходятся на значения \( i \geq 10 \). В этом и кроется причина некорректности этой задачи: очень велик коэффициент усиления ошибки!

    Теперь кратко обсудим метод поиска корней многочлена, не требующий, вообще говоря, предварительного определения границ корней. Этот метод — **метод парабол** — на самом деле применим не только к многочленам, но широкое распространение он получил именно для многочленов. Сходимость этого метода теоретически не доказана, но в практике вычислений корней многочленов не известны примеры, когда бы он не сходился или сходился медленно.

    Пусть требуется определить все корни алгебраического многочлена

    $$ P_n(z) = a_n z^n + a_{n-1} z^{n-1} + \dots + a_0 z^0, \quad a_0 \neq 0 $$

    с комплексными коэффициентами. Идея метода парабол заключается в следующем. Пусть заданы три попарно различных комплексных числа \( z_0, z_1, z_2 \) (т.е. метод 3-шаговый). Построим по этим числам, как по узлам, интерполяционный многочлен Лагранжа для \( P_n(z) \). Это будет многочлен 2-го порядка, корни которого несложно определить. Выберем в качестве \( z_3 \) тот его корень, который находится ближе к \( z_2 \), и в качестве следующей тройки чисел для интерполяции возьмём \( z_1, z_2, z_3 \) и т.д.

    Эмпирически установлено, что последовательность точек \( \{z_i\} \) всегда сходится к какому-либо корню. После того как этот корень найден, он выделяется, и вся процедура применяется к многочлену меньшей степени.

    **Замечание 1.** Перед удалением найденного корня его надо уточнить по исходному многочлену (например, методом Ньютона).

    **Замечание 2.** В качестве начальных точек выбирают \( z_1, z_2, z_3 \) так, чтобы итерации сходились к наименьшему по модулю корню.
    """)

    st.markdown("""
    Оценим потерю точности при понижении степени многочлена. Пусть корень (простой) \( x_1 \) вычислен с погрешностью \( \Delta x_1 \). Тогда в точке \( \tilde{x_1} = x_1 + \Delta x_1 \) многочлен \( P_n(\tilde{x_1}) \equiv P_n(x_1) + P'_n(x_1) \Delta x_1 = P'_n(x_1) \Delta x_1 \).

    При делении \( P_n(x) \) на \( (x - \tilde{x_1}) \) получим:

    $$ P_n(x) = P_{n-1}(x) (x - \tilde{x_1}) + P_n(\tilde{x_1}). $$

    Пусть \( x_2 \) — один из оставшихся корней (простых) \( P_n(x), \) который мы будем вычислять с помощью \( P_{n-1}(x). \) Обозначим его погрешность через \( \Delta x_2 \) и из (15) находим

    $$ P_{n-1}(x_2 + \Delta x_2) = P_{n-1}(x_2) + P'_{n-1}(x_2) \Delta x_2 = P_n(x_2) + P_n(\tilde{x_1}). $$

    Отсюда, так как

    $$ | \Delta x_2 | = | \Delta x_1 | \frac{| P'_n(x_1) |}{| P'_n(x_2) |}, $$

    Таким образом, потеря точности зависит от соотношения производных при значениях корней и может быть значительной.

    **Пример**:

    $$ P_{25}(x) = (x - 10^{-2})(x - 10^{-4})(x^2 - 16^{-2})(x^2 - 16^{-2})(x - 1). $$

    Для него

    $$ P_{25}(1) \equiv 1; \quad P_{25}(1/4) \equiv 1.4 \cdot 10^{-10}. $$

    Если корень \( x = 1 \) найден первым, то его исключение приведёт к большой потере точности для корней с \( |x| = 1/4. $$
    """)

def systemi_nonliniar_uravn():
    st.markdown("""
    ### 5.2. Системы нелинейных уравнений

    Системы нелинейных уравнений практически решают только итерационными методами. Пусть система имеет вид:

    $$ f_1(x_1, x_2, \dots, x_n) = 0, $$

    $$ f_2(x_1, x_2, \dots, x_n) = 0, $$

    $$ \dots $$

    $$ f_n(x_1, x_2, \dots, x_n) = 0. $$

    Для систем с большим числом переменных одним из первых шагов является отделение отдельных корней. Для двух нелинейных уравнений отделение можно произвести графически, построив на плоскости \( (x_1, x_2) \) графики кривых \( f_1(x_1, x_2) = 0 \) и \( f_2(x_1, x_2) = 0 \). Для большего числа переменных удовлетворительных способов подбора нулевых приближений нет.
    """)

def simple_iteracia_method():
    st.markdown("""
    ### 5.2.1. Метод простой итерации

    Пусть имеется система \( \bar{f}(\bar{x}) = 0 \) и нам удалось переписать её в эквивалентной форме:

    $$ \bar{x} = \bar{\varphi}(\bar{x}), \tag{17} $$

    где функции \( \varphi_i \), образующие вектор \( \varphi \), действительно определены и непрерывны в некоторой окрестности изолированного решения \( \bar{x}^* \) системы (16). Например, таким преобразованием может быть (при подходящих \( f_1, \dots, f_n \)) линейное преобразование

    $$ \bar{x} = \bar{x} + A \bar{f}(x), \tag{18} $$

    с несингулярной матрицей \( A \).

    Выбирая для системы (17) некоторое приближение \( \bar{x}_0 \), проводим итерации по формуле

    $$ \bar{x}_k = \bar{\varphi}(\bar{x}_{k-1}), \quad k = 1, 2, \dots. \tag{19} $$

    Если итерации сходятся, то они приводят к решению системы (17).
    """)

    st.markdown("""
    Для того чтобы установить условия сходимости этого процесса, дадим некоторые определения. Рассмотрим вектор-функцию

    $$ \bar{y} = \varphi(\bar{x}), \tag{20} $$

    для которой все компоненты вектора \( \varphi = (\varphi_1, \dots, \varphi_n) \) определены и непрерывны в известной области \( G \) действительного \( n \)-мерного пространства \( E_n \). Пусть значения \( \bar{y} = \varphi(\bar{x}) \) при \( \bar{x} \in G \) заполняют некоторую область \( G' \subset E_n \). В этом случае говорят, что уравнение (20) устанавливает отображение в области \( G \). Введем в пространстве \( E_n \) норму \( ||\bar{x}|| \) для вектора \( \bar{x} \). Например, можно выбрать такие нормы:

    $$ ||\bar{x}|| = \max |x_i|, \quad ||\bar{x}|| = \sqrt{\sum x_i^2}. $$

    Отображение (20) называется сжимающим в области \( G \), если существует \( 0 \leq q < 1 \), такое, что для любых \( x_1, x_2 \in G \) их образы \( \bar{y}_1 = \varphi(x_1), \bar{y}_2 = \varphi(x_2) \) удовлетворяют условию:

    $$ ||\bar{y}_1 - \bar{y}_2|| = ||\varphi(\bar{x}_1) - \varphi(\bar{x}_2)|| \leq q ||\bar{x}_1 - \bar{x}_2||. \tag{21} $$

    Вернемся теперь к итерационному процессу (19).

    #### Теорема 3.
    Пусть область \( G \) замкнута, \( \varphi(\bar{x}) \in G \) для \( \bar{x} \in G \) и отображение (17) является сжимающим в \( G \), т.е.

    $$ ||\varphi(\bar{x}_1) - \varphi(\bar{x}_2)|| \leq q ||\bar{x}_1 - \bar{x}_2||. $$

    Тогда, независимо от выбора \( \bar{x}_0 \in G \), процесс (19) сходится, т.е. существует

    $$ \bar{x}^* = \lim_{k \to \infty} \bar{x}_k, $$

    вектор \( \bar{x}^* \) — единственное решение (17) в \( G \) и справедлива оценка нормы

    $$ ||\bar{x}^* - \bar{x}_k|| \leq \frac{q^k}{1 - q} ||\bar{x}_1 - \bar{x}_0||. \tag{22} $$
    """)

    st.markdown("""
    #### Доказательство.
    Рассмотрим цепочку неравенств:

    $$ ||\bar{x}_{k+p} - \bar{x}^*|| = ||\bar{x}_{k+p} - \bar{x}_{k+p-1} + \dots + \bar{x}_k - \bar{x}^*|| $$

    $$ \leq ||\bar{x}_{k+p} - \bar{x}_{k+p-1}|| + \dots + ||\bar{x}_k - \bar{x}^*||. \tag{23} $$

    Для каждого слагаемого в правой части имеем

    $$ ||\bar{x}_{s+1} - \bar{x}_s|| = ||\varphi(\bar{x}_s) - \varphi(\bar{x}_{s-1})|| \leq q ||\bar{x}_s - \bar{x}_{s-1}||. $$

    Поэтому

    $$ ||\bar{x}_{k+p} - \bar{x}^*|| \leq ||\bar{x}_1 - \bar{x}_0|| \cdot \left( q^k + q^{k+1} + \dots + q^{k+p-1} \right) = \frac{q^k(1 - q^p)}{1 - q} ||\bar{x}_1 - \bar{x}_0||. \tag{24} $$

    Так как \( q < 1 \), то для любого \( \varepsilon > 0 \) существует \( N(\varepsilon) > 0 \), что при \( k > N \) и любом \( p > 0 \) будет

    $$ ||\bar{x}_{k+p} - \bar{x}_k|| \leq \varepsilon. $$

    Таким образом, для последовательности \( \{x_k\} \) выполнен критерий Коши, поэтому существует

    $$ \bar{x}^* = \lim_{k \to \infty} \bar{x}_k, $$

    и \( \bar{x}^* \in G \) в силу замкнутости \( G \). Вектор \( \bar{x}^* \) — решение уравнения (17), что следует из непрерывности \( \varphi \) после перехода к пределу в (19).

    Покажем, что \( \bar{x}^* \) — единственное решение уравнения (17) в \( G \). Пусть имеется другое решение \( \bar{x}_1^* \) и \( \bar{x}_2^* = \varphi(\bar{x}_2^*) \). Тогда

    $$ ||\bar{x}_1^* - \bar{x}_2^*|| \leq q ||\bar{x}_1^* - \bar{x}_2^*||. $$

    Откуда, поскольку \( -q + 1 > 0 \), \( \bar{x}_1^* = \bar{x}_2^* \) или \( \bar{x}_1^* = \bar{x}_2^* \). Из (24) при \( p \to \infty \) получим

    $$ ||\bar{x}^* - \bar{x}_k|| \leq \frac{q^k}{1 - q} ||\bar{x}_1 - \bar{x}_0||, $$

    что и требовалось доказать.

    #### Замечание.
    Из (23) имеем:

    $$ ||\bar{x}_{k+p} - \bar{x}_k|| \leq (q + q^2 + \dots + q^p) ||\bar{x}_k - \bar{x}_{k-1}|| \leq \frac{q}{1-q} ||\bar{x}_k - \bar{x}_{k-1}||. $$

    При \( p \to \infty \) получим

    $$ ||\bar{x}^* - \bar{x}_k|| \leq \frac{q}{1 - q} ||\bar{x}_k - \bar{x}_{k-1}||. $$

    Этим условием надо пользоваться для окончания итераций:

    $$ ||\bar{x}_k - \bar{x}_{k-1}|| \leq \varepsilon (1-q)/q. $$
    """)

def metod_newtona():
    st.markdown("""
    ### 5.2.2. Метод Ньютона

    Пусть известно некоторое приближение \( \bar{x}_p \) к корню \( \bar{x}^* \) уравнения \( \bar{f}(\bar{x}) = 0 \). Положим \( \Delta x = \bar{x} - \bar{x}_p \) и определим \( \Delta x^{(p)} \) из условия

    $$ \bar{f}(\bar{x}_p + \Delta x^{(p)}) = 0. $$

    Разложив функцию \( f_k \) в ряды и ограничиваясь первыми дифференциалами (т.е. производя линеаризацию), находим:

    $$ \sum_{i=1}^{n} \frac{\partial f_k (\bar{x}_p)}{\partial x_i} \Delta x_i^{(p)} = -f_k (\bar{x}_p), \quad 1 \leq k \leq n, $$

    где \( \Delta x_i^{(p)} = x_i^* - x_{i,p}. \)

    Мы получили линейную систему относительно \( \{ \Delta x_i^{(p)} \}. \) Решая её, находим эти приращения и определяем новое приближение по формуле:

    $$ \bar{x}_{p+1} = \bar{x}_p + \Delta x^{(p)}. $$

    Этот метод аналогичен методу простой итерации с

    $$ \varphi(\bar{x}) = \bar{x} - \left( \frac{\partial f}{\partial x} \right)^{-1} f(\bar{x}). $$

    Условия сходимости в координатном виде имеют сложный вид, и их редко удается проверить.

    Отметим только следующий результат: в окрестности корня итерации сходятся, если \( \det f'(x) \neq 0 \), причем сходимость квадратичная. 

    Критерий окончания итераций:

    $$ ||\bar{x}_p - \bar{x}_{p+1}|| \leq \varepsilon. $$

    #### Замечание. 
    Иногда матрицу производных вычисляют для сокращения работы, лишь при \( \bar{x}_0 \) и используют потом для всех \( \bar{x}_p \); скорость сходимости при этом может упасть до линейной, если \( \bar{x}_p \) далеко от \( \bar{x}^* \).

    В заключение этого раздела отметим, что метод простой итерации и метод Ньютона можно применять для решения уравнения \( f(z) = 0 \) в комплексной области, сводя его к системе двух уравнений, либо задавая начальное приближение для комплексных \( z \) (для вещественной функции \( f' \)).
    """)