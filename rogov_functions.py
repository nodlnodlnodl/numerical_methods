import streamlit as st

import streamlit as st

def mnk():
    st.markdown("### 3.4. Среднеквадратичное приближение (метод наименьших квадратов)")

    st.markdown("""
    До сих пор, рассматривая приближение функций, мы для их построения использовали критерий точного прохождения интерполирующей функции через узловые точки. Точность такой аппроксимации, как правило, гарантирована в небольшом интервале вблизи середины множества используемых узлов. Кроме того, нередки ситуации, когда опорные точки сильно искажены шумом (например, экспериментально измеренные значения некоторой величины со случайной ошибкой).

    Таким образом, если ставится задача получения достаточно точного приближения для функции $y(x)$ на заданном отрезке $a \leq x \leq b$ или же значения $y$ в узловых точках $x_1, x_2, ..., x_N$ сильно зашумлены, то широко используются методы, основанные на приближении в среднем. При этом наиболее распространённым методом является метод, основанный на минимизации среднеквадратичного отклонения (метод наименьших квадратов – МНК).
    """)

def mnogochlen_approksimashion():
    st.markdown("### 3.4.1. Дискретное задание функции, многомерная аппроксимация")

    st.markdown("""
    Пусть измеряется некоторая величина $y$ и сделано $N$ измерений, в ходе которых получены значения $y_1, y_2, ..., y_N$. Предположим, что ошибки измерений:
    """)
    st.markdown(r"$$\varepsilon_i = y - y_i$$")
    st.markdown("имеют случайный характер, независимы и:")
    st.markdown(r"$$\sum_{i=1}^N \varepsilon_i = 0.$$")
    st.markdown("""
    В этом случае в качестве оценки $\overline{y}$ величины $y$ выбирается такое значение, которое минимизирует сумму квадратов ошибок:
    """)
    st.markdown(r"$$f(\overline{y}) = \sum_{i=1}^N \varepsilon_i^2 = \sum_{i=1}^N (y - y_i)^2.$$")
    st.markdown("Определим это значение $\overline{y}$. Из условия минимума $f(y)$ имеем:")
    st.markdown(r"$$\frac{\partial f}{\partial y} \Bigg|_{y=\overline{y}} = 2 \sum_{i=1}^N (\overline{y} - y_i) = 0.$$")
    st.markdown("Следовательно:")
    st.markdown(r"$$\overline{y} = \frac{1}{N} \sum_{i=1}^N y_i.$$")
    st.markdown("""
    Таким образом, хорошо известный результат: среднее арифметическое в качестве оценки измеряемой величины берётся среднее значение нескольких измерений.
    """)

def linear_approcsimation():
    st.markdown("### 3.4.2. Непрерывное задание функции, линейная аппроксимация")

    st.markdown(
        r"Пусть на отрезке $a \leq x \leq b$ задана некоторая функция $y(x)$ и её надо аппроксимировать "
        r"с помощью линейной комбинации некоторых функций $f_k(x), \ k = 0, 1, \dots, M:$"
    )
    st.markdown(r"$$y_M = a_0 f_0 + a_1 f_1 + \dots + a_M f_M$$")

    st.markdown(
        r"Таким образом, чтобы $f(a_0, a_1, \dots, a_M) = \int_a^b \rho(x) [y(x) - y_M(x)]^2 dx$ "
        r"имела наименьшее значение, где $\rho(x)$ — весовая функция, "
        r"предполагается положительной, а система функций $f_0, f_1, \dots, f_M$ — линейно независимой."
    )

    st.markdown(r"Введём обозначение (скалярное произведение функций $q(x), \phi(x)$) как:")
    st.markdown(r"$$ (q, \phi) = \int_a^b \rho q \phi dx $$")

    st.markdown("Используя это обозначение, получим:")
    st.markdown(r"$$f(a_0, a_1, \dots, a_M) = (y, y) - 2 \sum_{k=0}^M a_k (y, f_k) + \sum_{k,m=0}^M a_k a_m (f_k, f_m)$$")

    st.markdown(
        r"Приравнивая к нулю производные от $f$ по $a_0, \dots, a_M$, получим систему уравнений:"
    )
    st.markdown(r"$$\sum_{m=0}^M (f_k, f_m) a_m = (y, f_k), \quad k = 0, 1, \dots, M.$$")

    st.markdown(
        r"Её определитель $\Delta = \det((f_k, f_m))$, называется определителем Грама функций $f_k$. "
        r"Для линейно независимых систем $\Delta \neq 0$, поэтому система всегда имеет решение."
    )

    st.markdown(
        r"Однако на практике непосредственно систему (22) при $M \geq 5$ решать сложно, так как "
        r"определитель Грама с ростом $M$ быстро убывает, что делает систему (22) малопригодной для вычислений."
    )

    st.markdown(
        r"Положение сильно упрощается, если $f_0, \dots, f_M$ образуют систему ортогональных функций."
    )

def ortogonal():
    st.markdown("### 3.4.3. Ортогональные функции")

    st.markdown("Рассмотрим теперь некоторые общие теоремы, поясняющие свойства ортогональных функций.")

    st.markdown(
        "**Определение 3.** Функции $f_0, f_1, ..., f_M$ называются линейно независимыми на отрезке $[a, b]$, если из равенства"
    )
    st.latex(r"a_0 f_0 + a_1 f_1 + \dots + a_M f_M = 0")
    st.markdown("на всём отрезке следует $a_0 = 0, a_1 = 0, ..., a_M = 0$.")

    st.markdown(
        "**Пример.** Функции $1, x, ..., x^M$ линейно независимы на любом отрезке $[a, b]$, так как многочлен"
    )
    st.latex(r"a_0 + a_1 x + \dots + a_M x^M")
    st.markdown("согласно основной теореме алгебры имеет не более $M$ корней.")

    st.markdown(
        "**Теорема 1.** Любая система непрерывных ортогональных на отрезке $[a, b]$ функций линейно независима."
    )

    st.markdown(
        "В самом деле, если $f_0, f_1, ..., f_M$ — такая система и $a_0 f_0 + \dots + a_M f_M \equiv 0$ при $a \leq x \leq b$,"
    )
    st.markdown("то для коэффициентов имеем")
    st.latex(r"a_j = \frac{1}{\lambda_j} \int_a^b \rho \cdot 0 \cdot f_j dx = 0.")

    st.markdown(
        "**Теорема 2.** Из любой системы линейно независимых функций $f_0, f_1, ..., f_M$ на отрезке $[a, b]$"
    )
    st.markdown("можно получить систему ортогональных функций на этом отрезке.")

    st.markdown("**Доказательство.** Рассмотрим следующий процесс (он называется процессом ортогонализации Шмидта):")

    st.latex(r"\lambda_0 = \int_a^b \rho(x) f_0^2 dx \quad (\rho(x) \geq 0 \text{ по условию})")

    st.markdown("тогда равенство $g_0(x) = \\frac{f_0(x)}{\sqrt{\lambda_0}}$ приводит нас к нормированной функции $g_0(x)$.")

    st.markdown("Пусть построены первые $j$ ортонормированных функций $g_i(x), i = 0, ..., j - 1.$")

    st.markdown("Положим")
    st.latex(r"F_j(x) = a_0 g_0 + \dots + a_{j-1} g_{j-1} + f_j(x).")

    st.markdown(
        "Функция $F_j$ отлична от нуля, так как $f_j$ линейно независимы, а каждая из $g_i$ — линейная комбинация $f_k, k \leq i$."
    )

    st.markdown("Определим $a_0, ..., a_{j-1}$ из условий ортогональности $F_j$ функциям $g_0, ..., g_{j-1}:$")
    st.latex(r"\int_a^b \rho F_j g_i dx = 0, \quad i = 0, 1, \dots, j - 1")

    st.markdown("Отсюда находим, подставляя выражение для $F_j$, что")
    st.latex(r"a_i + \int_a^b \rho f_j g_i dx = 0, \quad i = 0, 1, \dots, j - 1.")

    st.markdown("Следовательно, $F_j(x)$ определена, функцию $g_j$ определим так:")
    st.latex(r"g_j(x) = \frac{F_j(x)}{\sqrt{\lambda_j}}; \quad \lambda_j = \int_a^b \rho F_j^2 dx")

    st.markdown("Таким образом, шаг по индукции выполнен.")

    st.markdown("**Замечание.** На практике процесс ортогонализации Шмидта редко применяется для значений $M \geq 5$.")

    st.markdown(
        "Дело в том, что при численной ортогонализации потребности вычисления быстро приводят к тому, что "
        "очередная ортогональная функция становится малой."
    )

    st.markdown(
        "При нормировке ошибка только возрастает. Поэтому обычно пользуются аналитическими ортогональными системами функций."
    )

    st.markdown("**Теорема 3.** Коэффициенты Фурье $\{a_j\}$ функции $F(x)$ относительно ортонормированного семейства $\{g_j\}$")
    st.markdown("на отрезке $[a, b]$ удовлетворяют неравенству Бесселя:")
    st.latex(r"\sum_{j=0}^M a_j^2 \leq \int_a^b \rho F^2 dx.")

    st.markdown("**Доказательство.** Запишем очевидное неравенство:")
    st.latex(r"\int_a^b \rho \left(F - \sum_{i=0}^M a_i g_i(x)\right)^2 dx \geq 0")

    st.markdown("и раскроем скобки:")
    st.latex(
        r"0 \leq \int_a^b \rho F^2 dx - 2 \int_a^b \rho F \sum_{i=0}^M a_i g_i(x) dx + \int_a^b \rho \sum_{i=0}^M \sum_{j=0}^M a_i a_j g_i g_j dx ="
    )
    st.latex(r"= \int_a^b \rho F^2 dx - 2 \sum_{i=0}^M a_i^2 + \sum_{j=0}^M a_j^2.")

    st.markdown("Таким образом, теорема доказана.")

def orthogonal_polynomials():
    st.markdown("### 3.4.4. Ортогональные многочлены")

    st.markdown("""
    Важным подклассом ортогональных функций являются **ортогональные многочлены** на отрезке \([a, b]\),
    где $k$-й многочлен имеет степень $k$ $(k = 0, 1, \dots$).

    **Теорема 5.** $k$-й ортогональный на отрезке $[a, b]$ многочлен $P_k(x)$ имеет на $[a, b]$
    $(k$) действительных и различных корней.

    **Доказательство.** Предположим, что $P_k(x)$ имеет на $[a, b]$ $(r < k$) действительных корней $(x_1, x_2, ..., x_r$).
    Образуем произведение (с учётом кратности):

    """)

    st.markdown(r"$ \pi(x) = (x - x_1)(x - x_2) \dots (x - x_r). $")

    st.markdown("""
    Тогда:
    """)

    st.markdown(r"$$ \int_a^b \rho \pi(x) P_k(x) dx = 0 \quad (\rho \geq 0), $$")

    st.markdown("""
    так как функция $\pi(x)$ может быть разложена по $(P_0, P_1, \dots, P_r)$,
    а многочлен $(P_k(x)$) ортогонален им всем. Но такое равенство невозможно,
    так как подынтегральная функция знакопостоянна на $[a, b]$.
    Таким образом, многочлен $(P_k(x)$) имеет $(k$) корней.
    """)

    st.markdown("""
    Докажем, что они не кратные. Пусть какой-либо корень, например $(x_1$), имеет кратность $(n > 1$).
    Составим многочлен:
    """)

    st.markdown(r"$$ \pi(x) = (x - x_2) \dots (x - x_k) \begin{cases} 1, & n \text{ чётное,} \\ (x - x_1), & n \text{ нечётное.} \end{cases} $$")

    st.markdown("""
    Тогда $\pi(x) P_k(x)$ имеет тот же знак на $[a, b]$, что и $\\rho$,
    что противоречит ортогональности. Следовательно, все корни многочлена $P_k(x)$ простые.
    """)

    st.markdown("### Примеры ортогональных многочленов")

    st.markdown("**1. Многочлены Лежандра $P_n(x)$:**")

    st.markdown(r"""
    На отрезке $[a, b] = [-1, 1]$ при весовой функции $\rho(x) = 1$:
    $$ \int_{-1}^1 P_m(x) P_n(x) dx = \begin{cases} 0, & m \neq n, \\ \frac{2}{2n+1}, & m = n. \end{cases} $$
    """)

    st.markdown("""
    Первые многочлены Лежандра:
    """)

    st.markdown(r"""
    $$ P_0(x) = 1, \quad P_1(x) = x, \quad P_2(x) = \frac{1}{2}(3x^2 - 1), \quad P_3(x) = \frac{1}{2}(5x^3 - 3x). $$
    """)

    st.markdown("**2. Многочлены Лагерра $(L_n(x)$):**")

    st.markdown(r"""
    На отрезке $[a, b] = [0, \infty)$ при весовой функции $\rho(x) = e^{-x}$:
    $$ \int_0^\infty e^{-x} L_m(x) L_n(x) dx = \begin{cases} 0, & m \neq n, \\ 1, & m = n. \end{cases} $$
    """)

    st.markdown("**3. Многочлены Эрмита $(H_n(x)$):**")

    st.markdown(r"""
    На отрезке $([a, b] = (-\infty, \infty)$) при весовой функции $\rho(x) = e^{-x^2}$:
    $$ \int_{-\infty}^\infty e^{-x^2} H_m(x) H_n(x) dx = \begin{cases} 0, & m \neq n, \\ 2^n n! \sqrt{\pi}, & m = n. \end{cases} $$
    """)

    st.markdown("**4. Многочлены Чебышева $(T_n(x)$):**")

    st.markdown(r"""
    При весовой функции $\rho(x) = \frac{1}{\sqrt{1-x^2}}$ на $[-1, 1]$:
    $$ T_n(x) = \cos(n \arccos x). $$
    """)

    st.markdown("""
    Таким образом, ортогональные многочлены являются важным инструментом в приближении функций,
    решении дифференциальных уравнений и других задачах математического анализа.
    """)
